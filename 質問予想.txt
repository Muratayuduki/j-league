1. 技術・モデル選定に関する質問（★★★ 高確率）
Q1. 「なぜLightGBMやXGBoostではなく、CatBoostを選んだのですか？」

【回答案】 はい、他のモデルも検討しましたが、今回のデータセットはチーム名やスタジアム名といった**「カテゴリ変数」が非常に多かったため**です。 CatBoostはカテゴリ変数の処理に特化しており、パラメータ調整を細かく行わなくてもデフォルトで高い精度が出やすいため、今回のタスクに最適だと判断しました。

Q2. 「ターゲットエンコーディングのリーク対策について、具体的にどう実装しましたか？」

【回答案】 はい、K-Fold（クロスバリデーション）のループの中で処理を行いました。 具体的には、学習データを5分割し、学習に使う「4」のデータだけで平均値を計算して、それを残りの「1」の検証データに適用する形です。これにより、自分自身の数値を計算に含めてしまうリークを数学的に防いでいます。

Q3. 「K-Foldは5分割とのことですが、時系列（日付順）は考慮しましたか？」 （※もしランダム分割している場合、未来のデータで過去を予測するのはおかしいのでは？という鋭いツッコミです）

【回答案】 今回はシャッフルして分割しました。理由は、特定の季節（例えば開幕直後や終盤）にデータが偏ることを防ぎ、モデルの汎用性を高めたかったからです。 （※もし時系列分割していたなら：「はい、時系列を考慮して過去のデータのみで学習するようにしました」と答えてください）

2. データ・特徴量に関する質問（★★☆ 中確率）
Q4. 「NHKフラグが効いたのは分かりましたが、他の要因（天気やスタジアムの広さ）はどうでしたか？」

【回答案】 はい、もちろん**「スタジアムの収容人数（capa）」や「天気」もモデルには入れています。 ただ、特徴量重要度（Feature Importance）を確認したところ、収容人数という物理的な上限よりも、「ターゲットエンコーディング（チームの人気）」や「NHKフラグ（メディア露出）」**の方が、予測に対する貢献度が高かったです。

Q5. 「『ドリームマッチ（big_match）』は掛け算で作ったそうですが、足し算ではダメなのですか？」

【回答案】 はい、掛け算の方が効果的でした。 理由は、片方のチームだけ人気でも、もう片方が不人気だと観客は爆発的に増えませんが、両方とも人気チームの時は相乗効果で満員になる傾向があるからです。この「相乗効果」を表現するには、足し算よりも掛け算が適していました。

Q6. 「NHKフラグでBSを除外したとのことですが、BSでも少しは客が増えるのでは？」

【回答案】 おっしゃる通り、ゼロではないと思います。 しかしデータ分析の結果、NHK総合（地上波）は約3万人、BS放送は約1.8万人と、明らかに分布が異なっていました。BSを「あり」に含めてしまうと、**「すごく客が入る」という強いシグナルが薄まってしまう（ノイズになる）**ため、今回はあえて地上波のみに絞る判断をしました。

3. 結果・今後に関する質問（★☆☆ 変化球）
Q7. 「RMSE 3200という数字は、ビジネス的に見てどう評価しますか？」 （※誤差3200人は許容範囲か？という質問）

【回答案】 改善の余地はあると考えています。 平均観客数が約1.8万人ですので、誤差3000人というと約15〜20%のズレがあります。警備員の配置や仕入れの予測としては役立ちますが、より精密なコスト削減に使うには、さらに精度を上げる必要があると考えています。

Q8. 「さらなる精度向上のために、次は何をしますか？」

【回答案】 今回利用できなかった**「外部データ」の活用**です。 例えば、試合当日の近隣イベント情報や、チームの直近の勝敗（連勝中かどうか）、あるいは優勝がかかった試合かどうかといった「モメンタム（勢い）」の情報を追加できれば、さらに精度は上がると考えています。